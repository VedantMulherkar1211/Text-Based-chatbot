{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **AI PROJECT ON CHAT_BOT BY:**\n",
        "VEDANT MULHERKAR  BE  6-B\n",
        "\n",
        "AVINASH MANKAR    BE  5-B\n",
        "\n",
        "GANESH VISPUTE    BE  14-B "
      ],
      "metadata": {
        "id": "cxqZy76VDTT0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the required libraries**"
      ],
      "metadata": {
        "id": "UIHB4iQSXRZf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4BmyocFbb0MJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np   ## use for datastructure\n",
        "import nltk           ## it is natural language processing library\n",
        "import string         ## it is a library used to handle python string\n",
        "import random         ## use for machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85QE5FDSUKqU"
      },
      "source": [
        "**Importing and reading the corpus**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here we use file handling concept to handle the corpus "
      ],
      "metadata": {
        "id": "AjKWGaBMXjyL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jouIkYEkb9Pk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59d5e41b-e625-4523-dfe4-b64b08b58e63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ],
      "source": [
        "f=open('chatbot.txt','r',errors = 'ignore')\n",
        "raw_doc=f.read()\n",
        "raw_doc=raw_doc.lower() #Converts text to lowercase\n",
        "nltk.download('punkt') #Using the Punkt tokenizer\n",
        "nltk.download('wordnet') #Using the WordNet dictionary\n",
        "sent_tokens = nltk.sent_tokenize(raw_doc) #Converts doc to list of sentences \n",
        "word_tokens = nltk.word_tokenize(raw_doc) #Converts doc to list of words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmXgGkVeUSUb"
      },
      "source": [
        "**Example of sentance tokens**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the two sentence from the corpus"
      ],
      "metadata": {
        "id": "3h_NKTdaZFFc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Swu4WRVncPR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c802c364-a114-448e-fff1-a98f75b23ad6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nartificial intelligence (ai), the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings.',\n",
              " 'the term is frequently applied to the project of developing systems endowed with the intellectual processes characteristic of humans, such as the ability to reason, discover meaning, generalize, or learn from past experience.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "sent_tokens[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtkzd0KhUWJT"
      },
      "source": [
        "**Example of word tokens**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hcwrvmWicaLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e613a1c-e7de-4528-d059-8e8e96e2db3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['artificial', 'intelligence']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "word_tokens[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvvYcZZ9UbVD"
      },
      "source": [
        "**Text preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YbZllVqBcc78"
      },
      "outputs": [],
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLX8WBE4UgOr"
      },
      "source": [
        "**Defining the greeting function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dLOqphibchJM"
      },
      "outputs": [],
      "source": [
        "GREET_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\")\n",
        "GREET_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
        "def greet(sentence):\n",
        " \n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREET_INPUTS:\n",
        "            return random.choice(GREET_RESPONSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJhFmyRCUm4j"
      },
      "source": [
        "**Response generation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eo7Kv52HcjG0"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JEHZesw3cnNM"
      },
      "outputs": [],
      "source": [
        "def response(user_response):\n",
        "  robo1_response=''\n",
        "  TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "  tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "  idx=vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "  if(req_tfidf==0):\n",
        "    robo1_response=robo1_response+\"I am sorry! I don't understand you\"\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response = robo1_response+sent_tokens[idx]\n",
        "    return robo1_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q-iY_o1Utas"
      },
      "source": [
        "**Defining conversation start/end protocols**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wxzENVDgdNGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89628f2c-ab24-4858-cf50-6253ae78451c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOT: My name is Stark. Let's have a conversation! Also, if you want to exit any time, just type Bye!\n",
            "what is artificial intelligency\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOT: robots are the artificial agents acting in real world environment.\n",
            "history\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOT: I am sorry! I don't understand you\n",
            "what is robotics\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOT: what is robotics?\n",
            "robotics\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOT: what is robotics?\n",
            "hi\n",
            "BOT: hey\n",
            "bye\n",
            "BOT: Goodbye! Take care  LOVE YOU 3000 \n"
          ]
        }
      ],
      "source": [
        "flag=True\n",
        "print(\"BOT: My name is Stark. Let's have a conversation! Also, if you want to exit any time, just type Bye!\")\n",
        "while(flag==True):\n",
        "    user_response = input()\n",
        "    user_response=user_response.lower()\n",
        "    if(user_response!='bye'):\n",
        "        if(user_response=='thanks' or user_response=='thank you' ):\n",
        "            flag=False\n",
        "            print(\"BOT: You are welcome..\")\n",
        "        else:\n",
        "            if(greet(user_response)!=None):\n",
        "                print(\"BOT: \"+greet(user_response))\n",
        "            else:\n",
        "                sent_tokens.append(user_response)\n",
        "                word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
        "                final_words=list(set(word_tokens))\n",
        "                print(\"BOT: \",end=\"\")\n",
        "                print(response(user_response))\n",
        "                sent_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"BOT: Goodbye! Take care\"+\"  \"+\"LOVE YOU 3000 \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5yXpRQMXopU"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Building_a_chatbot_in_Python (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}